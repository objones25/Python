{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "9b8a3527",
   "metadata": {},
   "source": [
    "## Multinomial Naive Bayes on 20newsgroups Dataset"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b2145d81",
   "metadata": {},
   "source": [
    "In the question, you are asked to write code for classifying text data using Mulitnomial Naive Bayes.\n",
    "[The 20 Newsgroups data set](http://qwone.com/~jason/20Newsgroups/) is a benchmark dataset used for text classification and clustering tasks."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "04282d58",
   "metadata": {},
   "source": [
    "#### A Few Task Reminders:\n",
    "* Import required libraries.\n",
    "* Load the data and split into train, validation, and test sets. You can also perform k-fold cross-validation on the train set for better performance estimates.\n",
    "* Report the size of each class and perform any required data pre-processing.\n",
    "* In this case, the input data is text data. So, a goal of this assignment/question is to learn a few basics for working with text data. In particular, for the purpose of the assignment, I am only looking for learning what is Term Frequency–Inverse Document Frequency (TF-IDF) is and how to use the [TfidfVectorizer](https://scikit-learn.org/stable/modules/generated/sklearn.feature_extraction.text.TfidfVectorizer.html) function. \n",
    "* Train the Multinomial Naive Bayes Classifier on the data.\n",
    "* Make predictions and evaluate the model. Generate a confusion matrix and a classification report (e.g. using 'classification_report').\n",
    "* Summarize your findings and make sure you sufficiently document your code."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "68b47a79",
   "metadata": {},
   "source": [
    "**Note.** It is intentional that this problem assignment extends outside of what we have covered in class (i.e. text data pre-processing) and encourages more independent learning and exploration with ML hands-on experience and applications. I hope you would have fun with these type of questions and that they are not very stressful. Also, feedback is welcomed and encouraged!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "32a8a8de",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c07b7491",
   "metadata": {},
   "source": [
    "Let's load the data and take a look at the target names:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0446a424",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.datasets import fetch_20newsgroups\n",
    "\n",
    "data = fetch_20newsgroups()\n",
    "data.target_names"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7e428aab",
   "metadata": {},
   "source": [
    "For this problem, only consider the four categories below as our classes:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4d7877dc",
   "metadata": {},
   "outputs": [],
   "source": [
    "classes = ['comp.windows.x', 'rec.autos', 'sci.space', 'talk.religion.misc']\n",
    "train = fetch_20newsgroups(subset='train', categories=classes)\n",
    "test = fetch_20newsgroups(subset='test', categories=classes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5bb89b72",
   "metadata": {},
   "outputs": [],
   "source": [
    "# A sample in the train data\n",
    "print(train.data[5])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "524fe676",
   "metadata": {},
   "source": [
    "#### Term Frequency–Inverse Document Frequency (TF-IDF):\n",
    "\n",
    "In the vector space model of text data, each document can represented as $n_1$-dimensional vector, where $n_1$ is the size of the dictionary (number of terms) used to represent the documents in the dataset.\n",
    "Given $n_2$ documents, we construct a term-document matrix $X \\in \\mathbb{R}^{n_{1 \\times} n_2}$ where $X_{i j}$ corresponds to the significance of term $i$ in document $j$ using a Term frequency - Inverse Document Frequency (TF-IDF) representation:\n",
    "\n",
    "$$\n",
    "X_{i j}=T F_{i j} \\log \\left(\\frac{n_2}{D F_i}\\right)\n",
    "$$\n",
    "where,\n",
    "\\begin{align*}\n",
    "& \\text{Term Frequency: } \\quad  TF_{i j}=\\frac{f_{i, j}}{\\sum \\limits _{k \\in j} f_{k, j}} \\quad  \\text { where } f_{i j} \\text { is the number of times term $i$ appears in document $j$} \\\\\n",
    "& \\text{Document Frequency: } \\quad   D F_i= |\\{j \\in \\text { corpus } \\mid t_i \\in j\\}|: \\text{ number of documents containing term $i$}\n",
    "\\end{align*}\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "78128aa8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# For the purpose of the assignment, you can use the following:\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "\n",
    "n_features = 5000\n",
    "stop_words_list = nltk.corpus.stopwords.words('english') # optional for assignment\n",
    "vectorizer = TfidfVectorizer(max_features=n_features, stop_words=stop_words_list)\n",
    "vectors = vectorizer.fit_transform( ) #insert appropriate training set\n",
    "feature_names = vectorizer.get_feature_names()\n",
    "dense = vectors.todense()\n",
    "denselist = np.array(dense).transpose()  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2fc2604b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# For the purpose of the assignment, use default parameters and no need for tuning any hyperparameters or options.\n",
    "# For example, \n",
    "\n",
    "from sklearn.naive_bayes import MultinomialNB\n",
    "classifier = MultinomialNB()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e66abe69",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
